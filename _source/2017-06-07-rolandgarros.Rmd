---
layout: post
title: 'Who is talking about Roland-Garros?'
comments: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE, 
                      cache = TRUE)
```

I don't think rOpenSci's Jeroen Ooms can ever top the coolness of his [`magick` package](https://github.com/ropensci/magick) but I have to admit other things he's developped are not bad at all. He's recently been working on interfaces to Google compact language detectors 2 and 3 (the latter being more experimental). I saw [this cool use case](http://marcbeldata.github.io/Language-use-MP-Twitter/) and started thinking about other possible applications of the packages. 

I was very sad when I realized it was too late to try and download Eurovision tweets but then I also remembered there's [this famous tennis tournament](https://en.wikipedia.org/wiki/French_Open) going on right now, about which people probably tweet in various languages. I don't care about sports at all, but it seemed interesting to find out which languages were the most prevalent, and whether the results from the [`cld2`](https://github.com/ropensci/cld2) and [`cld3`](https://github.com/ropensci/cld3) packages are similar and whether they're similar to the language detection results from Twitter itself.


<!--more-->

# Getting the tweets

I'm using my usual `rtweet` recipe. Note that I currently experience some rate limits problems with the Twitter API, the real limits I get are lower than the ones indicated in the documentation which makes everything slow. Luckily for that small project I just needed one call to work.

```{r}
rg_tweets <- rtweet::search_tweets(q = "#RolandGarros2017",
                                   include_rts = FALSE,
                                   n = 18000)
save(rg_tweets, file = "data/2017-06-07-rolandgarros.RData")
```

I got `r nrow(rg_tweets)` tweets.

# Using the language detectors

Today I'm a happy naive user of language detectors, but more technical details can be found in their [respective](https://github.com/CLD2Owners/cld2) [README's](https://github.com/google/cld3#readme). It'd be difficult to have an easier interface than the two `cld2` and `cld3` packages.

```{r}
rg_tweets <- dplyr::mutate(rg_tweets, 
                           cld2_language = cld2::detect_language(text,
                                                                 lang_code = TRUE), 
                           cld3_language = cld3::detect_language(text))

```


# Looking at detected languages

Twitter output a language for `r round(sum(!is.na(rg_tweets$lang))/nrow(rg_tweets), digits = 2)*100`% of the tweets, `cld2` for `r round(sum(!is.na(rg_tweets$cld2_language))/nrow(rg_tweets), digits = 2)*100` and `cld3` for `r round(sum(!is.na(rg_tweets$cld3_language))/nrow(rg_tweets), digits = 2)*100`.

In the following I'm using a pipeline trick for not having to write the same code three times without having to write a function either.

```{r}
library("magrittr")
see_most_used_languages <- . %>%
  table() %>%
  broom::tidy() %>%
  dplyr::arrange(desc(Freq)) %>%
  head(n = 10) %>%
  knitr::kable()

rg_tweets$lang %>% see_most_used_languages
rg_tweets$cld2_language %>% see_most_used_languages
rg_tweets$cld3_language %>% see_most_used_languages
```

Let's have a look at lines with disagreements.

```{r}
#rg_tweets <- dplyr::mutate(rg_tweets, 
 #                          text = stringr::str_replace(text, "\\n", ""))
rg_tweets %>%
  dplyr::filter(!is.na(lang),
                !is.na(cld2_language),
                !is.na(cld3_language)) %>%
  dplyr::group_by(text) %>%
  dplyr::filter(length(unique(c(lang, cld2_language,
                              cld3_language))) != 1) %>%
  head(n = 50) %>%
  dplyr::select(text, lang, cld2_language,
         cld3_language)%>%
  knitr::kable()

```

```{r, cache = FALSE}
cluster::daisy(as.data.frame(t(dplyr::select(rg_tweets, lang, cld2_language, cld3_language))))

```

Compter d√©saccords/accords.

Bar plots des langues.
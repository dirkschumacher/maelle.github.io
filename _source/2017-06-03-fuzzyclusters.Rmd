---
layout: post
title: "Fuzzy clustering my Twitter followers"
comments: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE, 
                      cache = TRUE)
```

I've recently started using [fuzzy clustering](https://en.wikipedia.org/wiki/Fuzzy_clustering) at work. Fuzzy clustering is fuzzy because each observation can be assigned to several clusters. Furthermore, membership is defined by a grade, not a binary score. My application at work is serious and not finished yet, but I realized I could use the same method for fuzzy clustering my Twitter followers!

<!--more-->

# Who follows whom

For fuzzy clustering my Twitter followers I'll first need to define distances between them. I'm going to choose a very simple metric:

* If two of my followers follow each other, then the distance between them is 0.

* If only one of them follow the other one, then the distance between them is 1.

* If none of them follow the other one, then the distance between them is 2.

There'd be many other ways to define proximity between users, such as liking the same tweets, etc., but I'm no social media expert and maybe I'm a bit lazy.

In any case, now that I've decided on a metric I need to get the data! I'll first get all my followers, then all their followers, and then compute the metric for each pair of my followers.

## Getting my followers

```{r}
followers <- rtweet::get_followers(user = "ma_salmon")
head(followers)
```

## Getting their followers

The Twitter API limits the number of queries by time unit to the different endpoints. In order to get all the data I needed, I wrote a function for waiting when I had no more remaining queries. In case you wonder, one needs to be a bit patient, but I didn't need to stay in front of my computer the whole time. I'm wondering whether I could make a play on words... Would it be ridiculous to invent the term crock-post?

I added two error handling parts:

* One because apparently sometimes `rtweet::rate_limit` had a weird output (I couldn't reproduce the error so just dealt with it).

* Another one because at one point my husband unplugged our internet box so everything stopped (we're still married). He was the one suggesting me I saved the intermediary results, maybe he had planned this all along.

```{r}

get_followers_and_wait <- function(user){
  # don't re-query the same data twice
  exists <- paste0("followers", user, ".RData") %in% dir("data/2017-06-03-twitter")
  if(exists){
    # if it already exists use it
    load(paste0("data/2017-06-03-twitter/followers", user, ".RData"))
  }else{
    # otherwise query after checking the rate limit
    rates <- rtweet::rate_limit(token = rtweet::get_tokens(),
                              query = "followers/ids")
  if(rates$remaining == 0){
    try_sleeping <- try(Sys.sleep(as.numeric(rates$reset)*60), 
                        silent = TRUE)
    if(methods::is(try_sleeping, "try-error")){
      Sys.sleep(15*60)
    }
    
  }
  followers <- rtweet::get_followers(user = user)
  followers <- dplyr::mutate_(followers, followed_person = ~user)
  save(followers, file = paste0("data/2017-06-03-twitter/followers", user, ".RData"))
  }
  return(followers)
}

followers_followers <- purrr::map_df(followers$user_id,
                                     get_followers_and_wait)


head(followers_followers)
```

## Computing distances

I'll first find all combinations of followers. That `combn` function is handy!

```{r}
followers_pairs <- as.data.frame(t(combn(followers$user_id, 2)))
followers_pairs2 <- followers_pairs
followers_pairs2 <- dplyr::rename(followers_pairs2, V = V1, V1 = V2)
followers_pairs2 <- dplyr::rename(followers_pairs2, V2 = V)
followers_pairs <- dplyr::bind_rows(followers_pairs, followers_pairs2)
head(followers_pairs) 

```

Now I'll define the function for computing the distance corresponding to each pair.

```{r}
compute_distance <- function(pair, followers_followers){
  distance <- 2
  followers1 <- dplyr::filter_(followers_followers,
                                ~followed_person == pair$V1)
  if(pair$V2 %in% followers1$user_id){
    distance <- distance - 1
  }
  
  followers2 <- dplyr::filter_(followers_followers,
                                ~followed_person == pair$V2)
  if(pair$V1 %in% followers2$user_id){
    distance <- distance - 1
  }
  
  return(distance)
}

```

After that it's time to apply the function to each row of `followers_pairs`.

```{r}
followers_distances <- purrrlyr::by_row(followers_pairs,
                                        compute_distance,
                                        followers_followers = followers_followers,
                                        .to = "distance",
                                        .collate = "cols")
```

## Replacing user_id with names

The table I got is nice but in the end I want to use the names of accounts, not their user_id's which mean nothing to me.

```{r}
followers_names <- rtweet::lookup_users(followers$user_id)
followers_names <- dplyr::select_(followers_names, quote(user_id),
                                  quote(name))
followers_distances <- dplyr::left_join(followers_distances,
                                        followers_names,
                                        by = c("V1" = "user_id"))
followers_distances <- dplyr::rename_(followers_distances, .dots = c(user1 = "name"))

followers_distances <- dplyr::left_join(followers_distances,
                                        followers_names,
                                        by = c("V2" = "user_id"))
followers_distances <- dplyr::rename_(followers_distances, .dots = c(user2 = "name"))
followers_distances <- dplyr::arrange_(followers_distances, quote(distance))
head(followers_distances)
```

# Fuzzy clustering!

There are two main packages offering fuzzy clustering in R, `cluster` via the `fanny` function (interestingly many functions of that packages are first names), and the less established `fclust` package. The latter is more exhaustive, and was described [in a paper](http://www.sciencedirect.com/science/article/pii/S016501141500216X), but it was not updated since that paper's publication. Since I have no strong opinion about the method to be used, I'll just use the `cluster::fanny` function.

## Building the dissimilarity matrix

In the last part of the post I got a data.frame but what I need for using a clustering function is a dissimilarity matrix. I use the `fill = 1` argument in `tidyr::spread` because I know the only missing values are on the diagonale.

```{r}
followers_distance <- dplyr::select(followers_distances, distance, 
                                     user1, user2)

dissmatrix <- tidyr::spread(followers_distance, user2, distance, fill = 1)
dissmatrix <- dplyr::select(dissmatrix, - user1)
dissmatrix <- as.matrix(dissmatrix)
rownames(dissmatrix) <- colnames(dissmatrix)

```

## Clustering itself

```{r}
fannyx <- cluster::fanny(dissmatrix, 4, memb.exp = 1.1,
                         diss = TRUE)
```
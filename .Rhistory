if (!is.null(pg$result)) {
# go read Bob Rudis' post, in particular to read about
# the extra selector for "playlist"
data_frame(
date = date,
duration = xtract_nodes(pg$result, 'div[class="playlist"] *
span[class="time hidden-xs"]') %>% hm() %>% as.numeric(),
artist = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="titletag"]'),
title = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="artist"]'),
# this is the coolest/hardest part IMO
hour = purrr::map(0:23, ~{
if (.x<23) {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
} else {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x))
}
rep(.x, length(nod))
}) %>%
flatten_int()
)
} else {
closeAllConnections()
NULL
}
}
search_dates <- seq(from = ymd("2008-09-01"), to = ymd("2017-04-22"), by = "1 day")
# how you can make the progress bar work,
# estimate the time necessary for 5 requests
pb <- progress_estimated(length(search_dates[1:5]))
programs_df <- map_df(search_dates[1:5], get_one_day_program, pb=pb)
programs_df
pb <- dplyr::progress_estimated(length(search_dates[1:5]))
programs_df <- map_df(search_dates[1:5], get_one_day_program, pb=pb)
programs_df
?dplyr::progress_estimated
library("rvest")
library("purrr")
library("stringi")
library("lubridate")
library("tidyverse")
# using purrr::safely is cool because if the page
# is broken you get NULL as an output
s_read_html <- purrr::safely(read_html)
# helper for brevity
xtract_nodes <- function(node, css) {
html_nodes(node, css) %>% html_text(trim = TRUE)
}
get_one_day_program <- function(date=Sys.Date(),
base_url="http://www.radioswissclassic.ch/en/music-programme/search/%s",
pb=NULL) {
# progress bar magic!
if (!is.null(pb)) pb$tick()$print()
# that's the part where you're nice towards the website
Sys.sleep(sample(seq(0,1,0.25), 1)) # ideally, make this sample(5,1)
date <- ymd(date) # handles case where input is character ISO date
pg <- s_read_html(sprintf(base_url, format(date, "%Y%m%d")))
if (!is.null(pg$result)) {
# go read Bob Rudis' post, in particular to read about
# the extra selector for "playlist"
dplyr::data_frame(
date = date,
duration = xtract_nodes(pg$result, 'div[class="playlist"] *
span[class="time hidden-xs"]') %>% hm() %>% as.numeric(),
artist = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="titletag"]'),
title = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="artist"]'),
# this is the coolest/hardest part IMO
hour = purrr::map(0:23, ~{
if (.x<23) {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
} else {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x))
}
rep(.x, length(nod))
}) %>%
flatten_int()
)
} else {
closeAllConnections()
NULL
}
}
search_dates <- seq(from = ymd("2008-09-01"), to = ymd("2017-04-22"), by = "1 day")
# how you can make the progress bar work,
# estimate the time necessary for 5 requests
pb <- dplyr::progress_estimated(length(search_dates))
programs_df <- map_df(search_dates, get_one_day_program, pb=pb)
programs_df
get_one_day_program <- function(date=Sys.Date(),
base_url="http://www.radioswissclassic.ch/en/music-programme/search/%s",
pb=NULL) {
print(date)
# progress bar magic!
if (!is.null(pb)) pb$tick()$print()
# that's the part where you're nice towards the website
Sys.sleep(sample(seq(0,1,0.25), 1)) # ideally, make this sample(5,1)
date <- ymd(date) # handles case where input is character ISO date
pg <- s_read_html(sprintf(base_url, format(date, "%Y%m%d")))
if (!is.null(pg$result)) {
# go read Bob Rudis' post, in particular to read about
# the extra selector for "playlist"
dplyr::data_frame(
date = date,
duration = xtract_nodes(pg$result, 'div[class="playlist"] *
span[class="time hidden-xs"]') %>% hm() %>% as.numeric(),
artist = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="titletag"]'),
title = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="artist"]'),
# this is the coolest/hardest part IMO
hour = purrr::map(0:23, ~{
if (.x<23) {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
} else {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x))
}
rep(.x, length(nod))
}) %>%
flatten_int()
)
} else {
closeAllConnections()
NULL
}
}
search_dates <- seq(from = ymd("2008-09-01"), to = ymd("2017-04-22"), by = "1 day")
# how you can make the progress bar work,
# estimate the time necessary for 5 requests
pb <- dplyr::progress_estimated(length(search_dates))
programs_df <- map_df(search_dates, get_one_day_program, pb=pb)
date = ymd("2009-03-29")
date <- ymd(date) # handles case where input is character ISO date
pg <- s_read_html(sprintf(base_url, format(date, "%Y%m%d")))
class(ph)
class(pg)
lala=purrr::map(0:23, ~{
if (.x<23) {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
} else {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x))
}
rep(.x, length(nod))
}) %>%
flatten_int()
dplyr::data_frame(
date = date,
duration = xtract_nodes(pg$result, 'div[class="playlist"] *
span[class="time hidden-xs"]') %>% hm() %>% as.numeric(),
artist = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="titletag"]'),
title = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="artist"]'),
# this is the coolest/hardest part IMO
hour = purrr::map(0:23, ~{
if (.x<23) {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
} else {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x))
}
rep(.x, length(nod))
}) %>%
flatten_int()
)
get_one_day_program("2009-03-29")
date = "2009-03-29"
base_url
base_url="http://www.radioswissclassic.ch/en/music-programme/search/%s"
date <- ymd(date) # handles case where input is character ISO date
pg <- s_read_html(sprintf(base_url, format(date, "%Y%m%d")))
class(pg)
pg
lala=purrr::map(0:23, ~{
if (.x<23) {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
} else {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x))
}
rep(.x, length(nod))
}) %>%
flatten_int()
lala
length(lala)
unique(lala)
x=1
html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
} else {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x))
.x=1
html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
} else {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x))
nod
unique(lala)
html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
} else {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x))
.x
.x = 0
html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
} else {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x))
.x = 2
html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
.x = 6
html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')))
)
html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x, .x+1))
length(lala)
.x
html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x))
sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x, .x+1)
html_node(".//div[@id='06']")
html_node("div[@id='06']")
html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']", .x))
.x=1
html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']", .x))
html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x, .x+1))
.x
date
search_dates(date)
lala=get_one_day_program(date)
hour =  purrr::map(0:23, ~{
if (.x<23) {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')
and (following-sibling::div[@id='%02d'])]", .x, .x+1))
} else {
nod <- html_nodes(pg$result,
xpath=sprintf(".//div[@id='%02d']/following-sibling::div[contains(@class, 'item-row')]", .x))
}
rep(.x, length(nod))
}) %>%
flatten_int()
hour
lala=get_one_day_program("2015-05-05")
View(lala)
get_one_day_program <- function(date=Sys.Date(),
base_url="http://www.radioswissclassic.ch/en/music-programme/search/%s",
pb=NULL) {
print(date)
# progress bar magic!
if (!is.null(pb)) pb$tick()$print()
# that's the part where you're nice towards the website
Sys.sleep(sample(seq(0,1,0.25), 1)) # ideally, make this sample(5,1)
date <- ymd(date) # handles case where input is character ISO date
pg <- s_read_html(sprintf(base_url, format(date, "%Y%m%d")))
if (!is.null(pg$result)) {
# go read Bob Rudis' post, in particular to read about
# the extra selector for "playlist"
dplyr::data_frame(
date = date,
duration = xtract_nodes(pg$result, 'div[class="playlist"] *
span[class="time hidden-xs"]') %>% hm() %>% as.character(),
artist = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="titletag"]'),
title = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="artist"]'),
)
} else {
closeAllConnections()
NULL
}
}
lala=get_one_day_program("2015-05-05")
get_one_day_program <- function(date=Sys.Date(),
base_url="http://www.radioswissclassic.ch/en/music-programme/search/%s",
pb=NULL) {
print(date)
# progress bar magic!
if (!is.null(pb)) pb$tick()$print()
# that's the part where you're nice towards the website
Sys.sleep(sample(seq(0,1,0.25), 1)) # ideally, make this sample(5,1)
date <- ymd(date) # handles case where input is character ISO date
pg <- s_read_html(sprintf(base_url, format(date, "%Y%m%d")))
if (!is.null(pg$result)) {
# go read Bob Rudis' post, in particular to read about
# the extra selector for "playlist"
dplyr::data_frame(
date = date,
duration = xtract_nodes(pg$result, 'div[class="playlist"] *
span[class="time hidden-xs"]') %>% hm() %>% as.character(),
artist = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="titletag"]'),
title = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="artist"]')
)
} else {
closeAllConnections()
NULL
}
}
lala=get_one_day_program("2015-05-05")
View(lala)
get_one_day_program <- function(date=Sys.Date(),
base_url="http://www.radioswissclassic.ch/en/music-programme/search/%s",
pb=NULL) {
print(date)
# progress bar magic!
if (!is.null(pb)) pb$tick()$print()
# that's the part where you're nice towards the website
Sys.sleep(sample(seq(0,1,0.25), 1)) # ideally, make this sample(5,1)
date <- ymd(date) # handles case where input is character ISO date
pg <- s_read_html(sprintf(base_url, format(date, "%Y%m%d")))
if (!is.null(pg$result)) {
# go read Bob Rudis' post, in particular to read about
# the extra selector for "playlist"
dplyr::data_frame(
date = date,
duration = xtract_nodes(pg$result, 'div[class="playlist"] *
span[class="time hidden-xs"]') %>% hm(),
artist = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="titletag"]'),
title = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="artist"]')
)
} else {
closeAllConnections()
NULL
}
}
lala=get_one_day_program("2015-05-05")
View(lala)
get_one_day_program <- function(date=Sys.Date(),
base_url="http://www.radioswissclassic.ch/en/music-programme/search/%s",
pb=NULL) {
print(date)
# progress bar magic!
if (!is.null(pb)) pb$tick()$print()
# that's the part where you're nice towards the website
Sys.sleep(sample(seq(0,1,0.25), 1)) # ideally, make this sample(5,1)
date <- ymd(date) # handles case where input is character ISO date
pg <- s_read_html(sprintf(base_url, format(date, "%Y%m%d")))
if (!is.null(pg$result)) {
# go read Bob Rudis' post, in particular to read about
# the extra selector for "playlist"
dplyr::data_frame(
date = date,
duration = xtract_nodes(pg$result, 'div[class="playlist"] *
span[class="time hidden-xs"]') %>% hm(),
datetime = update(date, hour = hour(duration), minute = minute(duration)),
artist = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="titletag"]'),
title = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="artist"]')
)
} else {
closeAllConnections()
NULL
}
}
lala=get_one_day_program("2015-05-05")
View(lala)
rm(list = ls())
library("rvest")
library("purrr")
library("stringi")
library("lubridate")
library("tidyverse")
# using purrr::safely is cool because if the page
# is broken you get NULL as an output
s_read_html <- purrr::safely(read_html)
# helper for brevity
xtract_nodes <- function(node, css) {
html_nodes(node, css) %>% html_text(trim = TRUE)
}
get_one_day_program <- function(date=Sys.Date(),
base_url="http://www.radioswissclassic.ch/en/music-programme/search/%s",
pb=NULL) {
# progress bar magic!
if (!is.null(pb)) pb$tick()$print()
# that's the part where you're nice towards the website
Sys.sleep(sample(seq(0,1,0.25), 1)) # ideally, make this sample(5,1)
date <- ymd(date) # handles case where input is character ISO date
pg <- s_read_html(sprintf(base_url, format(date, "%Y%m%d")))
if (!is.null(pg$result)) {
# go read Bob Rudis' post, in particular to read about
# the extra selector for "playlist"
dplyr::data_frame(
date = date,
duration = xtract_nodes(pg$result, 'div[class="playlist"] *
span[class="time hidden-xs"]') %>% hm(),
datetime = update(date, hour = hour(duration), minute = minute(duration)),
artist = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="titletag"]'),
title = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="artist"]')
)
} else {
closeAllConnections()
NULL
}
}
search_dates <- seq(from = ymd("2008-09-01"), to = ymd("2017-04-22"), by = "1 day")
# how you can make the progress bar work,
# estimate the time necessary for 5 requests
pb <- dplyr::progress_estimated(length(search_dates))
programs_df <- map_df(search_dates, get_one_day_program, pb=pb) %>%
programs_df <- programs_df %>%
select(- duration) %>%
mutate(datetime = force_tz(datetime, tz = "Europe/Zurich"))
programs_df
save(programs_df, file = "data/radioswissclassic_programs_radioedit.RData")
programs_df <- map_df(search_dates, get_one_day_program, pb=pb)
library("rvest")
library("purrr")
library("stringi")
library("lubridate")
library("tidyverse")
# using purrr::safely is cool because if the page
# is broken you get NULL as an output
s_read_html <- purrr::safely(read_html)
# helper for brevity
xtract_nodes <- function(node, css) {
html_nodes(node, css) %>% html_text(trim = TRUE)
}
get_one_day_program <- function(date=Sys.Date(),
base_url="http://www.radioswissclassic.ch/en/music-programme/search/%s",
pb=NULL) {
# progress bar magic!
if (!is.null(pb)) pb$tick()$print()
# that's the part where you're nice towards the website
Sys.sleep(sample(seq(0,1,0.25), 1)) # ideally, make this sample(5,1)
date <- ymd(date) # handles case where input is character ISO date
pg <- s_read_html(sprintf(base_url, format(date, "%Y%m%d")))
if (!is.null(pg$result)) {
# go read Bob Rudis' post, in particular to read about
# the extra selector for "playlist"
dplyr::data_frame(
date = date,
duration = xtract_nodes(pg$result, 'div[class="playlist"] *
span[class="time hidden-xs"]') %>% hm(),
datetime = update(date, hour = hour(duration), minute = minute(duration)),
artist = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="titletag"]'),
title = xtract_nodes(pg$result, 'div[class="playlist"] * span[class="artist"]')
)
} else {
closeAllConnections()
NULL
}
}
search_dates <- seq(from = ymd("2008-09-01"), to = ymd("2017-04-22"), by = "1 day")
# how you can make the progress bar work,
# estimate the time necessary for 5 requests
pb <- dplyr::progress_estimated(length(search_dates))
programs_df <- map_df(search_dates, get_one_day_program, pb=pb)
programs_df <- programs_df %>%
select(- duration) %>%
mutate(datetime = force_tz(datetime, tz = "Europe/Zurich"))
programs_df
head(programs_df$date)
head(programs_df$datetime)
names(programs_df)
programs_df <- programs_df %>%
select(- duration) %>%
mutate(datetime = force_tz(datetime, tz = "Europe/Zurich"))
programs_df <- programs_df %>%
dplyr::select(- duration) %>%
dplyr::mutate(datetime = force_tz(datetime, tz = "Europe/Zurich"))
save(programs_df, file = "_source/data/radioswissclassic_programs_radioedit.RData")
length(search_dates)
length(unique(programs_df$date))
servr::jekyll()
servr::jekyll()
servr::jekyll()
install.packages("quantreg")
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
?quantreg::rq
programs_df <- dplyr::arrange(programs_df, time)
programs_df <- dplyr::mutate(programs_df,
duration = difftime(lead(timedate, 1),
timedate,
units = "min"))
programs_df <- dplyr::mutate(programs_df,
duration = ifelse(duration > 60,
NA, duration))
programs_df <- dplyr::mutate(programs_df,
hour = as.factor(lubridate::hour(timedate)))
library("quantreg")
fit1 <- rq(duration ~ hour, tau = .75, data = programs_df)
fit1 <- rq(duration ~ hour, tau = .75, data = as.data.frame(programs_df))
install.packages(c("animation", "aRxiv", "batchtools", "broom", "chron", "cleanNLP", "curl", "DBI", "deldir", "e1071", "EML", "emojifont", "expm", "fftwtools", "forecast", "formatR", "gdtools", "geojsonio", "ggiraph", "ggthemes", "giphyr", "gistr", "goftest", "googleAuthR", "gsl", "h2o", "highlight", "htmltools", "lattice", "leaflet", "lme4", "magick", "maptools", "memoise", "MGLM", "mvtnorm", "nlme", "NLP", "openair", "pathological", "pbapply", "pbkrtest", "plotly", "polyclip", "psych", "ranger", "rbison", "RcppArmadillo", "RcppEigen", "rcrossref", "Rd2roxygen", "readr", "readxl", "rebird", "revealjs", "rgbif", "rgdal", "rgeos", "rmarkdown", "ropenaq", "roxygen2", "rpart", "rsconnect", "rsvg", "shiny", "showtext", "SparseM", "spatstat", "spdep", "splancs", "spocc", "statmod", "surveillance", "tidyr", "tm", "tseries", "V8", "viridis", "XML", "zoo"))
servr::jekyll()
servr::jekyll()
